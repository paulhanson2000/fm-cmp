---
format:
  html:
    code-fold: show
    code-tools: true
toc: true
execute:
  eval: false # TODO TMP
---

TODO: stamp each render/run of this script with a UUID, and add log/<method>/<UUID> dirs \
TODO: print out "before and after" tables to make it clearer what the code is doing

# Libraries
```{r lib, eval=T}
#| output: false
library(kableExtra)
library(digest)
library(data.table)
library(SeqArray)
library(SNPRelate)
library(refpanelutil)
```

## Convenience functions
```{r eval=T}
"%ni%" <- Negate("%in%")
fix_yaml <- function(a) {if(is.list(a)) sapply(a, function(a2) lapply(a2, fix_yaml)) else a}
```

# Load Configs
<!--- Don't cache this block. Or if you do, add cache.extra=tools::md5sum("filenames") -->
```{r config-files, eval=T}
misc_config <- fix_yaml(yaml::read_yaml("config/misc.config"))
data_config <- fread("config/data.config")
loci_config <- fread("config/loci-min.config")
anno_config <- fread("config/anno.config")
  ld_config <- fread("config/ld.config")
 chr_nm_map <- fread("config/ucsc_chr_names_map.txt")
```

<!--- TODO: Instead of raw HTML <details>, use result-folding planned in Quarto 1.4 https://github.com/quarto-dev/quarto-cli/issues/341). -->
<details>
<summary>Click to expand</summary>
```{r display-misc-config, eval=T, echo=F}
cat(yaml::as.yaml(misc_config))
```
```{r display-other-configs, eval=T, echo=F, results="asis"}
small_tbl <- function(df, cap) df %>%
  kable(caption=paste("<p style='text-align: left'><strong>",cap,"</strong></p>")) %>%
  kable_styling("striped") %>%
  row_spec(0, background="#DDDDDD") %>%
  scroll_box(height="200px")

small_tbl(data_config,"data_config");             cat("\n\n <!--- -->\n\n") # https://bookdown.org/yihui/rmarkdown-cookbook/kable.html#generate-multiple-tables-from-a-for-loop
small_tbl(loci_config,"loci_config");             cat("\n\n <!--- -->\n\n")
small_tbl(anno_config,"anno_config");             cat("\n\n <!--- -->\n\n")
small_tbl(chr_nm_map, "ucsc_chr_names_map.txt");  cat("\n\n <!--- -->\n\n")
if(misc_config$ref_panel == "my_ld") small_tbl(ld_config,"ld_config")
#for(df in list(data_config, loci_config, anno_config, ld_config, chr_nm_map)) {
#  print(small_tbl(df))
#  cat("\n\n <!--- -->\n\n") 
#}
```
</details>

```{r hash, eval=T}
#| code-fold: false
config_hash <- digest(list(misc_config, data_config, loci_config, anno_config, ld_config, chr_nm_map), algo="md5")
```

Unique hash of the above config files: **`r config_hash`**\
If two runs of this pipeline have the same hash, they used the exact same configs. 

## Hands-free hardcoded reference panels
```{r hardcoded-refpanels, eval=T, cache=T, cache.extra = misc_config$ref_panel}
if(misc_config$ref_panel == "1kg") {
  misc_config$ref_panel_ref_genome <- "hg19"
  misc_config$ref_panel <- paste0("http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr",1:22,".phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz")
  misc_config$ref_panel <- c(misc_config$ref_panel, "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chrX.phase3_shapeit2_mvncall_integrated_v1c.20130502.genotypes.vcf.gz")
  #misc_config$ref_panel <- c(misc_config$ref_panel, "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chrY.phase3_integrated_v2b.20130502.genotypes.vcf.gz") # TODO: different samples?
  #misc_config$ref_panel <- c(misc_config$ref_panel, "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chrMT.phase3_callmom-v0_4.20130502.genotypes.vcf.gz") # TODO: different samples?
  misc_config$sample_info_file <- "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel"
  misc_config$sample_id_field <- "sample"
  misc_config$sample_ancestry_field <- "super_pop"
} else
if(misc_config$ref_panel == "1kg_30x") {
  misc_config$ref_panel_ref_genome <- "hg38"
  misc_config$ref_panel <- paste0("http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20220422_3202_phased_SNV_INDEL_SV/1kGP_high_coverage_Illumina.chr",1:22,".filtered.SNV_INDEL_SV_phased_panel.vcf.gz")
  misc_config$ref_panel <- c(misc_config$ref_panel, "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20220422_3202_phased_SNV_INDEL_SV/1kGP_high_coverage_Illumina.chrX.filtered.SNV_INDEL_SV_phased_panel.v2.vcf.gz")
  misc_config$sample_info_file <- "http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/20130606_g1k_3202_samples_ped_population.txt"
  misc_config$sample_id_field <- "SampleID"
  misc_config$sample_ancestry_field <- "Superpopulation"
} else
if(misc_config$ref_panel == "gnomad_1kg+hgdp") {
  misc_config$ref_panel_ref_genome <- "hg38"
  misc_config$ref_panel <- paste0("https://gnomad-public-us-east-1.s3.amazonaws.com/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.hgdp_tgp.chr",c(1:22,"X","Y"),".vcf.bgz") # Only the Amazon links work, otherwise corrupts halfway through vcfs2Gds().

  # gnomAD sample info file has wacky JSON stuff. Extract what we need to a temporary file.
  sample_info <- fread(cmd="curl https://gnomad-public-us-east-1.s3.amazonaws.com/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.hgdp_1kg_subset_sample_meta.tsv.bgz | zcat") # TODO: save to scratch and read if already present to avoid need for internet access
  sample_info$pop <- sapply(sample_info$gnomad_population_inference, function(x) ifelse(is.na(x), NA, jsonlite::fromJSON(x)$pop))
  sample_info[pop=="nfe", pop:="eur"]
  if(misc_config$gnomad_count_fin_as_eur) sample_info[pop=="fin", pop:="eur"]
  # gnomAD also recommends using this "high_quality" sample filter: https://gnomad.broadinstitute.org/news/2021-10-gnomad-v3-1-2-minor-release/
  sample_info <- sample_info[high_quality==TRUE]
  fwrite(sample_info[,.(s, pop)], paste0(misc_config$scratch_dir,"gnomAD_sample_info.txt"))

  misc_config$sample_info_file <- paste0(misc_config$scratch_dir,"gnomAD_sample_info.txt")
  misc_config$sample_id_field <- "s"
  misc_config$sample_ancestry_field <- "pop"
}
```

## Validate input
```{r input-validation, eval=T}
# TODO:
# The rest of the code is cleaner under the assumption all input datasets are valid, and error messages early save the user time.
# data
  # data files exist (and maybe check if they're valid too? Can use fread(...,nrows=3) to quickly peek)
  # all cols required by all misc_config$fm_methods is there are specified for every data file
  # valid reference genomes
  # every dataset's ancestry is a valid ancestry in the reference panel too
    # robust to whether these ancestry names are capitalized or not
# loci: make sure valid reference genomes
# anno
  # Make sure no "+"s in anno names b/c will mess w/ fgwas.
  # Check anno files all exist (and are proper bed format too? maybe nah)
  # Make sure only one annotation method is specified at a time (e.g. not both fgwas and polyfun. But paintor or sparsepro are fine)
# misc
  # Ref panel
    # Check files exist if custom reference panel
    # Sample info
      # Check that sample_ancestry_field exists in either the sample_info_file or VCF/BCF/GDS file(s)
      # Check that sample_id_field exists in sample_info_file if given
      # Check that sample_info IDs match ref_panel (should do this even for hard-coded ref_panels for uniformity)
    # If pre-computed LD
      # Make sure no NAs or NaNs
      # Warn if some loci in config.ld & config.loci don't match
      # Warn if some ancestries in config.ld & config.data don't match
if(!dir.exists(misc_config$scratch_dir)) stop(paste0("Scratch directory ", misc_config$scratch_dir, " does not exist. Please create it, or change your desired scratch directory in config.misc."))
```

## `liftOver` loci and annotations
We need versions of `anno.config` for the sumstats' build(s), to add annotations to the sumstats.\
We need versions of `loci.config` for the sumstats' and reference panel's build(s), to subset those big files to only the parts we need.\

Note: It is **not recommended  to use `liftOver` on individual variants** (sources: [1](http://genome.ucsc.edu/FAQ/FAQreleases.html#snpConversion), [2](https://groups.google.com/a/soe.ucsc.edu/g/genome/c/wkgf5DXpwEc/m/wDpsjyDVCQAJ), [3](https://annovar.openbioinformatics.org/en/latest/articles/dbSNP/)). Lifting variants by matching their rsID across builds is more accurate (although even rsIDs can be ambiguous ([source](https://gnomad.broadinstitute.org/help/why-is-this-variant-linked-to-the-wrong-dbsnp-rsid))).\

Therefore, summary stats are lifted via rsIDs later (if their build is not already the same as the reference panel's). Here we lift only the *regions* of `loci.config` and `anno.config`.

### Convert to UCSC naming scheme
`liftOver` requires the UCSC naming scheme (e.g. "chr#", not "#", and "hg19" instead of "GRCh37"), so we need to convert.\
[**GRCh37**, **hg19**, and **b37** genome builds are equivalent — except in mitochondria and some contigs (exactly what is different nobody seems to know... see this somewhat dubious [source](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711-GRCh37-hg19-b37-humanG1Kv37-Human-Reference-Discrepancies)). Beyond that, they have different naming conventions: hg19 uses "chr#" instead of "#". I believe GRCh**38** and hg**38** *are* fully equivalent though.]{.aside}
```{r ucsc-naming, eval=T, cache=T, cache.inval = config_hash}
#| output: false
# TODO: Maybe remove this whole code block and just tell the user they must use "hg" naming scheme, and just tell them hg18=grch36, etc. in a comment in the config?
# TODO: could be more elegant to use a reference genomes synonyms file or something
lapply(list(data_config, loci_config, anno_config), function(config_file) {
  config_file[tolower(ref_genome) %in% c("grch36"       ), ref_genome := "hg18"]
  config_file[tolower(ref_genome) %in% c("grch37", "b37"), ref_genome := "hg19"]
  config_file[tolower(ref_genome) %in% c("grch38"       ), ref_genome := "hg38"]
  config_file[, ref_genome := factor(ref_genome)]
})
if(tolower(misc_config$ref_panel_ref_genome) %in% c("grch36"       )) misc_config$ref_panel_ref_genome <- "hg18"
if(tolower(misc_config$ref_panel_ref_genome) %in% c("grch37", "b37")) misc_config$ref_panel_ref_genome <- "hg19"
if(tolower(misc_config$ref_panel_ref_genome) %in% c("grch38"       )) misc_config$ref_panel_ref_genome <- "hg38"

# TODO: would be good if it didn't turn already-properly-named chrs to NA. I.e. should be idempotent
loci_config$chr <- chr_nm_map$to[match(loci_config$chr, chr_nm_map$from)]
loci_config$chr <- factor(loci_config$chr, levels=unique(chr_nm_map$to))
```

### `liftOver`
```{r liftover, eval=T, cache=T, cache.inval = config_hash}
if(!dir.exists("out/liftover")) dir.create("out/liftover", recursive=T)

loci_configs <-
lapply(union(data_config$ref_genome, misc_config$ref_panel_ref_genome), function(dg) {
  loci_config_bed_format <- data.table(
    chrom      = loci_config$chr,
    chromStart = loci_config$pos_min,
    chromEnd   = loci_config$pos_max,
    name       = loci_config$locus
  )

  loci_config_lifted <- do.call(rbind,
  lapply(unique(loci_config$ref_genome), function(lg) {
    loci_of_a_ref_genome_bed <- loci_config_bed_format[loci_config$ref_genome == lg] 
    if(dg != lg)
      liftOver(loci_of_a_ref_genome_bed,
               from_build = lg, to_build = dg,
               liftover_bin="third_party/liftover/liftOver")
    else
      loci_of_a_ref_genome_bed
  })
  )

  setnames(setDT(loci_config_lifted), c("chr","pos_min","pos_max","locus"))
  loci_config_lifted$chr   <- factor(loci_config_lifted$chr, levels=unique(chr_nm_map$to))
  loci_config_lifted$locus <- factor(loci_config_lifted$locus, levels=unique(loci_config$locus))
  fwrite(loci_config_lifted, paste0("out/liftover/config.loci.",dg), sep=' ')
  loci_config_lifted
})
names(loci_configs) <- union(data_config$ref_genome, misc_config$ref_panel_ref_genome)

anno_configs <- 
lapply(unique(data_config$ref_genome), function(dg) {
  lifted_anno_config <- copy(anno_config)
  sapply(1:nrow(anno_config), function(i) {
    ag <- anno_config[i,ref_genome]
    if(dg != ag) {
      lifted_bed_file <- paste0("out/liftover/",anno_config[i,name],"-lifted_to_",dg,".bed")
      liftOver(anno_config[i,bed_file],
               out_file = lifted_bed_file, 
               from_build = ag, to_build = dg,
               liftover_bin="third_party/liftover/liftOver")

      lifted_anno_config[i, `:=`(ref_genome = dg,
                                 bed_file = lifted_bed_file)]
    }
  })
  fwrite(lifted_anno_config, paste0("out/liftover/config.anno.",dg), sep=' ')
  lifted_anno_config
})
names(anno_configs) <- unique(data_config$ref_genome)
```


# Load data
## GWAS summary stats
```{r load-sumstats}
#| output: false
# TODO: Temporary hard-coded DIAMANTE meta-analyzed sumstats for fgwas.
#data_config <- rbind(data_config, data_config[1,]) 
#data_config[4, `:=`(filepath="data/DIAMANTE2022/sumstat/DIAMANTE-TA.sumstat.txt",
#                    n=NA, ancestry=NA, eaf_col=NA,
#                    b_col=10, se_col=11, p_col=12)]

sumstats <- lapply(1:nrow(data_config), function(r) {
  loci <- loci_configs[[ data_config[r,ref_genome] ]] # Loci with coords lifted to the current data file's ref genome

  cols <- data_config[r, c( chr_col, pos_col, rs_id_col, effect_allele_col, other_allele_col, eaf_col, b_col, se_col, z_col, p_col, n_col)]
  cols <- setNames(cols, c("chr",   "pos",   "rs_id",   "a1",              "a0",             "eaf",   "b",   "se",   "z",   "p",   "n"   ))
  cols <- cols[!is.na(cols)]

  sumstat <- fread(data_config[r,filepath])
  sumstat <- sumstat[, ..cols]
  setnames(sumstat, names(cols))

  sumstat$chr <- chr_nm_map$to[match(sumstat$chr, chr_nm_map$from)]
  sumstat$chr <- factor(sumstat$chr, levels=unique(chr_nm_map$to))

  sumstat <- do.call(rbind, lapply(1:nrow(loci), function(i) {
    sumstat[ chr == loci$chr[i]     &
             pos >= loci$pos_min[i] &
             pos <= loci$pos_max[i] ][, locus := loci$locus[i]]
  }))
  if("eaf" %in% names(sumstat)) sumstat <- sumstat[eaf > 0 & eaf < 1]

  sumstat[,`:=`(a0=toupper(a0), a1=toupper(a1))]

  # Infer some columns from the others if possible. For axample, z-score can be calculated from β and SE.
  if(data_config[r, is.na(z_col) & !is.na(b_col) & !is.na(se_col)]) sumstat[, z := b/se]
  # TODO: reverse-engineer N from p/z/se/af if n_col not given?

  # TODO: meh, maybe just compare w/ $chr $pos etc. directly instead of creating these IDs?
    # No, ID col is good b/c passing ids of this format is the clearest interface for functions like vcfs2Gds and ldCalc
    # But then again, could just reconstruct the ids e/t time? No, too much, b/c'd have to do the Reduce around the paste(), too much.
  #if(data_config[r, !is.na(chr_col) & !is.na(pos_col) & !is.na(other_allele_col) & !is.na(effect_allele_col)])
    #sumstat$chrpos_id <- paste0(sumstat$chr,":",sumstat$pos,"_",sumstat$a0,"_",sumstat$a1) # NOTE: using chr:pos_ref_alt instead of all ":"s, but doesn't matter, split by both : and _ at all times anyways.

  # TODO: add support for chrpos_id_col. Infer chr, pos, a0, a1 cols if chrpos ids are given

  sumstat
})
names(sumstats) <- basename(data_config$filepath)
```

```{r TMP-PRINT}
print(nrow(sumstats[[1]]))
```


## Reference panel
```{r load-refpanel}
if(any(misc_config$ref_panel != "my_ld")) { # TODO: replace this and future such checks w/ a proper ref_panel_is_ld variable or s/t
  regions_bed_format <- loci_configs[[misc_config$ref_panel_ref_genome]][,.(chr,pos_min,pos_max)]
  # TODO: if ref and ALL sumstats are of the same build, could be more specific and give the chr,pos-1,pos of the variants in the sumstats as regions instead. Would make resuling ref panel file leaner and faster to obtain over the internet.

  # Create unique filename based on input parameters. If already exists, don't need to recompute.
  ref_gds_file <- paste0(misc_config$scratch_dir,"/",digest::digest(list(misc_config$ref_panel,regions_bed_format,chr_nm_map)),".gds")
  if(!file.exists(ref_gds_file)) {

    if(tools::file_ext(misc_config$ref_panel[1]) == "gds") {
      # Make a copy s.t. the user's original GDS file will not be modified.
        # Also slim the copy down to only the required regions.
      tmp <- seqOpen(misc_config$ref_panel)
      seqSetFilterChrom(tmp, regions_bed_format$chr, # TODO: use chr_nm_map, to deal w/ chr naming styles wackier than just "chr" prefix (handled by default ignore.chr.prefix="chr"). And then rename the chrs in the copy.
                   from.bp = regions_bed_format$pos_min,
                     to.bp = regions_bed_format$pos_max)
      seqExport(ref, ref_gds_file, info.var="", fmt.var="")
      seqClose(misc_config$ref_panel); rm(tmp)

    } else { # Take given VCF(s) and convert to GDS
      vcfs2Gds(files = misc_config$ref_panel, 
               output_name = ref_gds_file,
               regions = regions_bed_format,
               exclude_annos = c("FORMAT","INFO"),
               chr_nm_map = chr_nm_map,
               scratch_dir = misc_config$scratch_dir)
    }
  }
  ref <- seqOpen(ref_gds_file, readonly=F)
}

{ if(all(misc_config$ref_panel == "my_ld")) ref_panel_ids <- NULL # TODO: Reduce(union, etc.. Maybe Reduce(union, lapply(ld_config$filepath, fread, nrow=1)))
  else                                      ref_panel_ids <- seqGetData(ref,"annotation/id") }

# If ref panel has no rsids, get them
if(!any(grepl("^rs", ref_panel_ids))) { # TODO: Actually can skip this if ref panel and ALL sumstats are of the same build. Can just use ch:pos:allele for e/t then.

  # Much faster to download the dbSNP file and access it locally. TODO: maybe if ~<500 variants, just use URL
  dbsnp_vcf <- {
    if      (misc_config$ref_panel_ref_genome == "hg19") "GCF_000001405.25.gz"
    else if (misc_config$ref_panel_ref_genome == "hg38") "GCF_000001405.40.gz"
    else stop("TODO")
  }
  if(!file.exists(dbsnp_vcf)) {
    message("Downloading dbSNP file locally for faster access.") # TODO: better message
    download.file(url = paste0("https://ftp.ncbi.nih.gov/snp/latest_release/VCF/",dbsnp_vcf)) # TODO: put in better place than just working dir
    download.file(url = paste0("https://ftp.ncbi.nih.gov/snp/latest_release/VCF/",dbsnp_vcf,".tbi")) # TODO: put in better place than just working dir
  }

  bcftools_cmd <- bcftoolsPipableCmd(
    files = dbsnp_vcf,
    regions = data.table(seqGetData(ref,"chromosome"), seqGetData(ref,"position")-1, seqGetData(ref,"position")),
    query = "%ID\t%CHROM\t%POS\t%REF\t%ALT\n",
    chr_nm_map = chr_nm_map,
    scratch_dir = misc_config$scratch_dir)

  dbsnp_var_id_info <- fread(cmd = bcftools_cmd, col.names=c("rs_id", "chr", "pos", "ref", "alt"))
  ref_var_id_info <- data.table(chr=seqGetData(ref,"chromosome"), pos=seqGetData(ref,"position"), ref=seqGetData(ref,"$ref"), alt=seqGetData(ref,"$alt")) # TODO: for my_ld, make this same thing but from parsed chr:pos IDs

  tmp <- dbsnp_var_id_info[
           ref_var_id_info,
           on=.(chr,pos)
         ][
           mapply(i.ref,i.alt,ref,alt, FUN = function(ir,ia,r,a)
             all( c(ir,ia) %in% c(r,strsplit(a,',')[[1]]) ))
         ][
           ref_var_id_info,
           on=c("chr","pos",i.ref="ref",i.alt="alt"),
           roll=T,
           mult="first"
         ]
  stopifnot(identical(tmp$chr,   ref_var_id_info$chr)) # sanity check (TODO: rm once sane)
  stopifnot(identical(tmp$pos,   ref_var_id_info$pos))
  stopifnot(identical(tmp$i.ref, ref_var_id_info$ref))
  stopifnot(identical(tmp$i.alt, ref_var_id_info$alt))

  seqAddValue(ref, "annotation/id", tmp$rs_id, replace=T)
  # NOTE: these rsIDs added to the reference panel may include duplicates and/or NAs.
  # Dupllicate rsIDs are indicative of variants in the reference panel which have been merged in newer versions of dbSNP.
  # Missing    rsIDs are indicative of...                                           withdrawn in newer versions of dbSNP.

  # TODO: use rsID synonyms and stuff to try to keep as many variants as possible?

  rm(tmp, ref_var_id_info, dbsnp_var_id_info)
}
```

## Reference panel `sample_info`
```{r load-sample-info}
if(any(misc_config$ref_panel != "my_ld")) {
  sample_info <- fread(misc_config$sample_info_file)[, c(misc_config$sample_id_field, misc_config$sample_ancestry_field), with=F]
  setnames(sample_info, c("id","ancestry"))
  sample_info$ancestry <- factor(toupper(sample_info$ancestry))
}
```


# Filter sumstats using ref panel
Only keep variants which:\
1. Are within the loci specified in `config.loci`
2. Have ancestry-specific MAF above `r misc_config$maf_threshold` for that sumstat file's ancestry
3. Are present in both sumstats and reference panel
```{r filter-sumstats}
#| output: false
loci <- loci_configs[[misc_config$ref_panel_ref_genome]]

seqSetFilterChrom(ref, as.character(loci$chr), loci$pos_min, loci$pos_max, is.num=F, intersect=T)

samples_of_each_ancestry <- tapply(sample_info$id, INDEX=sample_info$ancestry, FUN = identity) 
ancestries_maf_mac_miss <- lapply(samples_of_each_ancestry, function(samples_of_an_ancestry) {
    seqSetFilter(ref, sample.id = samples_of_an_ancestry)
    seqGetAF_AC_Missing(ref, minor=T)
})
seqResetFilter(ref, variant=F)

invisible(sapply(data_config$ancestry, function(anc) if(anc %ni% names(ancestries_maf_mac_miss)) { print(paste("ERROR: Ancestry",anc,"mentioned in config.data is not an ancestry in the reference panel:", paste(collapse=", ", names(ancestries_maf_mac_miss)), "\nPlease remove this dataset from config.data, or if this was just a typo, change the ancestry name to match one of those in the reference panel.")); stop() })) # TODO: this belongs earlier, when loading in the data. But a nice sanity check to have for now.

sumstats <- mapply(sumstats, data_config$ancestry, SIMPLIFY=F, FUN = function(s, anc) {
  ancestry_maf_mac_miss <- ancestries_maf_mac_miss[[anc]]

  seqResetFilter(ref)
  variants2keep <- rep(T, seqSummary(ref,verbose=F)$num.variant)
  variants2keep <- !duplicated(seqGetData(ref,"annotation/id")) & # TODO: just keeping the first duplicate. Could keep more variants by finding rsID synonyms?
                        !is.na(seqGetData(ref,"annotation/id"))
  if(!anyNA(filt(ref)))                           variants2keep <- variants2keep & filt(ref) == "PASS"
  if(!is.null(ancestry_maf_mac_miss)) { # TODO: bad, silently fails if typo in ancestry name
    if(!is.null(misc_config$maf_threshold))         variants2keep <- variants2keep & ancestry_maf_mac_miss$af   > misc_config$maf_threshold
    if(!is.null(misc_config$mac_threshold))         variants2keep <- variants2keep & ancestry_maf_mac_miss$ac   > misc_config$mac_threshold
  
                                                    variants2keep <- variants2keep & ancestry_maf_mac_miss$miss < 1
    if(!is.null(misc_config$missingness_threshold)) variants2keep <- variants2keep & ancestry_maf_mac_miss$miss < misc_config$missingness_threshold
  }
  # TODO: multiallelic filter using seqNumAllele()?

  seqSetFilter(ref, action = "push+intersect", variant.sel = variants2keep)

  s <- s[rs_id %in% seqGetData(ref,"annotation/id")]
  seqFilterPop(ref)
  s
})

# TODO: tmp
#sumstats_TA_cpy <- sumstats[[4]]
#ancestres_rsids_union <- Reduce(union, lapply(sumstats[1:3], '[', j=rs_id))
#sumstats[[4]] <- sumstats[[4]][rs_id %in% ancestries_rsids_union]
#rm(ancestries_rsids_union)
```


# Annotation
## Add Annotation Columns
```{r anno-cols}
if(!is.null(misc_config$anno_method)) {
# TODO: PAINTOR's script is fast, but would be more elegant to do in R than system calls to Python

# TODO: transition from doing separately for each ancestry to once on the trans-ancestry file
#anno_colss <- mapply(sumstats, 1:length(sumstats), SIMPLIFY=F, FUN = function(sumstat,i) {
anno_cols <- {
  sumstat <- sumstats[[4]] # TODO: the trans-ancestry meta-analyzed sumstats, please remove hard coding
  scratch <- misc_config$scratch_dir
  py_env_dir <- paste0(scratch,"/py_env/")

  fwrite(sumstat[, .(chr,pos)], paste0(scratch,"/sumstat"), sep=' ')
  writeLines(anno_config$bed_file, paste0(scratch,"/config.anno.tmp"))

  if(!dir.exists(py_env_dir)) {
    system(paste0("virtualenv ",py_env_dir,"; ",
                  "source ",py_env_dir,"bin/activate; ",
                  "python -m pip install numpy"))
  }
  system(paste0("source ",py_env_dir,"bin/activate; ",
                "python3 third_party/PAINTOR_V3.0/PAINTOR_Utilities/AnnotateLocus.py",
                  " -l ",scratch,"/sumstat -c chr -p pos",
                  " -i ",scratch,"/config.anno.tmp",
                  " -o ",scratch,"/anno_cols.txt"))

  anno_cols <- fread(paste0(scratch,"/anno_cols.txt"))
  names(anno_cols) <- anno_config$name

  unlink("config.anno.tmp")
  unlink(paste0(scratch,"/anno_cols.txt"))
  unlink(paste0(scratch,"/sumstat"))
  anno_cols 
}

sumstats[[4]] <- cbind(sumstats[[4]], anno_cols)
rm(anno_cols)
}
```

## fgwas
```{r fgwas}
if("fgwas" %in% misc_config$anno_method) {
  if(!dir.exists("in/fgwas")) dir.create("in/fgwas", recursive=T)
  if(!dir.exists("out/fgwas")) dir.create("out/fgwas")
  
  # Takes the sumstats, formats them in a way fgwas likes, then gets the annotations of the best-likelihood model.
  s <- sumstats[[4]]
  s[,SEGNUMBER := as.integer(locus)]
  s <- s[, .SD, .SDcols=c("rs_id","chr","pos","z","se","SEGNUMBER",anno_config$name)]
  setnames(s,           c("SNPID","CHR","POS","Z","SE","SEGNUMBER",anno_config$name))
                                   # fgwas requires specific header names.
  s <- s[order(SEGNUMBER,CHR,POS)] # fgwas requires ordering by SEGNUMBER (if -fine option), and chr and pos.
  #s[,chr := paste0("chr",CHR)]     # fgwas uses UCSC "chr#" syntax, not just the number.
  s[,`:=`(F=0, N=0)]               # fgwas errors if missing F or N col, even though overridden by SE.
  
  input_filename <- paste0("in/fgwas/fgwas_input_sumstats.gz")
  fwrite(s, input_filename, sep=' ', compress="gzip")
  
  source("inc/fgwasFxns.R")

  annos      <- fgwasPruneInsignifAnnos(input_filename, anno_config$name, fgwas_bin="third_party/fgwas/src/fgwas-100_iter", silent=T)
  if(length(annos)==0) { message("No annotations were significant.") }
  else {
    annos      <- fgwasGetBestLikelihoodAnnos(input_filename, annos, fgwas_bin="third_party/fgwas/src/fgwas-1000_iter", silent=T)
    l          <- fgwasGetBestXValidationPenalty(input_filename, annos, fgwas_bin="third_party/fgwas/src/fgwas-1000_iter", silent=T)
    best_annos <- fgwasGetBestXValidatedAnnos(input_filename, annos, l$best_penalty, l$best_xv_llk, fgwas_bin="third_party/fgwas/src/fgwas-1000_iter", silent=T)
    
    best_model <- paste(collapse='+', best_annos)
    system(paste("third_party/fgwas/src/fgwas-1000_iter -fine -print",
      "-i", input_filename,
      "-w", best_model,
      "-o", "out/fgwas/results"))
    
    fgwas_results <- fread(paste0("out/fgwas/results.bfs.gz"))
  }
}
```

# Subset
Split the summary stats into sets of subsets, one per locus.
```{r subset-sumstats}
# TODO: update w/ tapply. B/c now that liftover'd, one locus can have multiple regions.
  # Don't have to do now for the DIAMANTE data since all loci are made of one region in b37.
  # This change is only required to support datasets of multiple reference genomes, or multi-region user-specified loci.

#sumstats4 <- sumstats[[4]] # TODO: temporary until meta-analysis implemented...
#sumstats[[4]] <- NULL

subset_sumstatss <- lapply(1:nrow(loci_config), function(r) {
                    mapply(sumstats, data_config$ref_genome, SIMPLIFY=F, FUN = function(s, ref_genome) {
                    #mapply(sumstats, data_config$ref_genome[1:3], SIMPLIFY=F, FUN = function(s, ref_genome) { # TODO: hardcoded [1:3]
  s <- s[order(rs_id)] # important becuase PAINTOR requires all variants to be in the same order for every group
  s <- s[ chr == loci_configs[[ref_genome]][r,chr]     &
          pos >= loci_configs[[ref_genome]][r,pos_min] &
          pos <= loci_configs[[ref_genome]][r,pos_max] ]

  if(nrow(s)==0) NULL else s
})})
names(subset_sumstatss) <- loci_config$locus


# TODO: ugly, but not sure what else to do?
for(l in loci_config$locus) {
  if(all(sapply(subset_sumstatss[[l]],is.null))) {
    message("No summary stats for locus ",l," have any variants, so removing it.")
    subset_sumstatss[[l]] <- NULL
    loci_config <- loci_config[locus!=l]
    for(i in 1:length(loci_configs)) {
      loci_configs[[i]] <- loci_configs[[i]][locus!=l]
    }
  }
}
rm(i,l)
```


# LD
Calculate LD per ancestry per locus.
```{r ld}
if(!dir.exists(paste0(misc_config$scratch_dir,"/ld"))) dir.create(paste0(misc_config$scratch_dir,"/ld"))

# TODO: more elegant place to put this?
seqSetFilter(ref, variant.sel= seqGetData(ref,"annotation/id") %ni% c(NA,"") & !duplicated(seqGetData(ref,"annotation/id")))

lds <- sapply(loci_config$locus,     simplify=F, function(l) {
sapply(unique(data_config$ancestry), simplify=F, function(anc) {
    outfile_name <- paste0(misc_config$scratch_dir,"ld/",l,"-",anc,".ld.gz")
    if(file.exists(outfile_name)) return(fread(outfile_name))

    samples_of_an_ancestry <- samples_of_each_ancestry[[anc]]
    sumstats_of_an_ancestry <- subset_sumstatss[[l]][which(data_config$ancestry == anc)]
    common_rs_ids_in_sumstats_of_an_ancestry <- Reduce(union, lapply(sumstats_of_an_ancestry, '[', j=rs_id))

    # TODO: not generalizable if multiple datasets in an ancestry with different rsIDs and/or different effect alleles.
      # Simple solution would be in data pre-proc: just flip alleles & β & z & etc..
      # For now w/ just the DIAMANTE data w/ one dataset per ancestry it's fine. Even the different ancestries have matching a0/a1, I checked.
    a_sumstat_of_an_ancestry <- sumstats_of_an_ancestry[[1]][rs_id %in% common_rs_ids_in_sumstats_of_an_ancestry]
    #print(paste(identical(a_sumstat_of_an_ancestry$rs_id, common_rs_ids_in_sumstats_of_an_ancestry)))
    ref_alleles <- a_sumstat_of_an_ancestry$a0

    ld <- ldCalc(ref, 
                 sample_ids = samples_of_an_ancestry,
                 variant_ids = common_rs_ids_in_sumstats_of_an_ancestry,
                 ref_alleles = ref_alleles,
                 n_threads = 6L)

    fwrite(ld, outfile_name, sep=' ', na="NA", compress="gzip")
    ld
})})

# TODO: have to move this inside the above `sapply`s now that I am not storing all LDs in mem at once anymore
# Some variants might have been removed from the LD matrices due to having NaNs. Remove these from the sumstats too
# TODO: find out what is causing these NaNs, and maybe won't need this paragraph at all.
subset_sumstatss <-
  sapply(loci_config$locus, simplify=F, function(l) {
  mapply(basename(data_config$filepath), data_config$ancestry, SIMPLIFY=F, FUN = function(f,a) {
  subset_sumstatss[[l]][[f]][ rs_id %in% colnames(ldss[[l]][[a]]) ]
})})
```


# Run Fine-Mapping Methods
## SuSiEx
SuSiEx is a command-line python program. It expects the following:\
A summary stats file, as follows:\ 
TODO: make nice table\
The β column _must_ be named "BETA" or "OR", but besides that they may be named arbitrarily.
```{r}
if("susiex" %in% misc_config$fm_methods) {

# Prep input
if(!dir.exists("in/susiex")) dir.create("in/susiex", recursive=T)
# TODO: ensure data contains the required columns
lapply(loci_config$locus, function(l) {
mapply(subset_sumstatss[[l]], names(sumstats), FUN=function(s, nm) {
  s <- s[, .(chr,pos,rs_id,a0,a1,b,se,p)]
  setnames(s, old="b", new="BETA", skip_absent=T)
  fwrite(s, paste0("in/susiex/",l,"-",nm), sep='\t')
})})

# TODO: PLINK stuff
  # NOTE TO SELF: see daily note 230605. Letting SuSiEx recompute its own LD for now just to get things working.


# Run
if(!dir.exists("out/susiex")) dir.create("out/susiex", recursive=T)
err <- lapply(1:nrow(loci_config), function(r) {
  system(paste("third_party/SuSiEx/bin/SuSiEx",
               "--sst_file", paste(collapse=',', paste0("in/susiex/",loci_config[r,locus],"-",names(sumstats))),
               "--n_gwas",   paste(collapse=',', data_config$n),
               "--ld_file",  paste(collapse=',', paste0(misc_config$scratch_dir,"/ld/",loci_config[r,locus],"-",unique(data_config$ancestry),"-susiex")), # TODO: compute own LD
               "--ref_file data/ref/1kg/plink_format/eas/g1000_eas,data/ref/1kg/plink_format/eur/g1000_eur,data/ref/1kg/plink_format/sas/g1000_sas", # TODO:
               "--plink plink", # TODO:
               "--out_dir out/susiex",
               "--out_name", loci_config[r,locus],
               #"--level 0.95", # Default
               "--chr ", loci_config[r,chr],
               "--bp ", paste(sep=',', loci_config[r,pos_min], loci_config[r,pos_max]),
               "--chr_col", paste(collapse=',', rep(1,nrow(data_config))),
               "--bp_col",  paste(collapse=',', rep(2,nrow(data_config))),
               "--snp_col", paste(collapse=',', rep(3,nrow(data_config))),
               "--a1_col",  paste(collapse=',', rep(4,nrow(data_config))),
               "--a2_col",  paste(collapse=',', rep(5,nrow(data_config))),
               "--eff_col", paste(collapse=',', rep(6,nrow(data_config))),
               "--se_col",  paste(collapse=',', rep(7,nrow(data_config))),
               "--pval_col",paste(collapse=',', rep(8,nrow(data_config))),
               "--maf", misc_config$maf_threshold, # TODO: 0 is not allowed, why?
               #"--min_purity 0.5", # Default. Even if some credsets are impure and not practically useful, still want all the posteriors for comparison purposes. TODO: Purity filter of 0 causes errors for some loci, see daily note 230621. 0.01 is totally low enough but it not being 0 still bothering me. Low priorty to look into.
               "--mult-step True",
               "--keep-ambig True",
               "--threads", 6L # TODO: make more general, or allow input
               # defaults: --max_iter=100, --pval_thresh=1e-5, --tol=1e-4, --n_sig=5
  ))
})
# TODO: use "err" to print a warning if SuSiEx fails for some loci, and specify the loci.

}
```

## PAINTOR
### Prep Input
PAINTOR only works on variants shared by ALL input datasets.\
TODO: desc
```{r}
if(!dir.exists("in/paintor")) dir.create("in/paintor")
# input.files
writeLines(unique(loci_config$locus), "in/paintor/input.files")

# Locus files. Format:
# rsid  pop1_z  pop2_z ...
#  rs1   -3.14  -1.337
#  ... <no NAs allowed>

# Annotation files. Format:
# annot1  annot2 ...
# 0 or 1  0 or 1 
# Must have same number of rows and order as locus file.

desired_rs_idss <- sapply(loci_config$locus, simplify=F, function(l) {
  signif_rs_ids <- Reduce(union,     lapply(subset_sumstatss[[l]], '[', j=rs_id)) # NOTE: optional hardcoded p threshold here
  common_rs_ids <- Reduce(intersect, lapply(subset_sumstatss[[l]], '[',           j=rs_id))
  desired_rs_ids <- intersect(signif_rs_ids, common_rs_ids)
})

lapply(unique(loci_config$locus), function(l) {
  desired_rs_ids <- desired_rs_idss[[l]]
  desired_sumstats <- lapply(subset_sumstatss[[l]], function(s) s[rs_id %in% desired_rs_ids]) # We sorted before, so all sumstats' rsids are in the same order even after subsetting. 

  paintor_locus_file <- Reduce(cbind, lapply(desired_sumstats, '[', j=z), desired_rs_ids) # Can add more metadata than just rsid if you want
  colnames(paintor_locus_file) <- c("rs_id", paste0(names(sumstats),"_z"))
  fwrite(paintor_locus_file, paste0("in/paintor/",l), sep=' ')

  paintor_anno_file <- desired_sumstats[[1]][, .SD, .SDcols=anno_config$name]
  fwrite(paintor_anno_file, paste0("in/paintor/",l,".annotations"), sep=' ')
})

# LD files. Format: Pearson r, space-delim'd, no header, not compressed, must have same number of rows and order as locus file.
lapply(unique(loci_config$locus), function(l) {
  desired_rs_ids <- desired_rs_idss[[l]]
       ld_filenames <- paste0(misc_config$scratch_dir,"/ld/",l,"-",unique(data_config$ancestry),".ld.gz")
  desired_filenames <- paste0(                 "in/paintor/",l,".ld_",unique(data_config$ancestry))
  paintor_lds <- lapply(ld_filenames, function(f) as.matrix(fread(f)))
  mapply(ldss[[l]], desired_filenames, SIMPLIFY=F, FUN = function(ld, nm) {
    desired_subset <- colnames(ld) %in% desired_rs_ids
    ld <- ld[desired_subset, desired_subset]
    fwrite(ld, nm, sep=' ', col.names=F)
  })
}) # TODO: A more elegant way? Unfortunately PAINTOR insists having all its input files in a single dir, so that means either cluttering in/ld/, changing filesnames in in/ld/ to use weird naming conventions, or making copies.... And PAINTOR doesn't accept compression so copies it is I guess....
# AND it wants to take in all loci at once, which means you have to store ALL the (decompressed!) LD files at once w/o being able to delete them as you go.

# Must still use a dummy all-0s file even if no annotations requested
#lapply(loci_config$locus, function(l) {
#  desired_rsids <- desired_rs_idss[[l]]
#  
#  writeLines(c("dummy_annot", rep(0,length(desired_rsids))),
#             paste0("in/paintor/",l,".annotations"))
#})
```

### Run PAINTOR
```{r}
if(!dir.exists("out/paintor")) dir.create("out/paintor", recursive=T)
system(paste("third_party/PAINTOR_V3.0/PAINTOR",
               "-input in/paintor/input.files",
               "-in in/paintor/",
               "-out out/paintor/",
               "-Zhead",  paste(collapse=',', paste0(names(sumstats),"_z")),
               "-LDname", paste(collapse=',', paste0("ld_",data_config$ancestry)),
               #"-annotations dummy_annot",
               "-annotations", paste(collapse=',', anno_config$name), # TODO: temporary, just use all annotations
               "-enumerate 1"
))
```
