---
title: `r Sys.Date()`
format: html
toc: true
---

TODO: stamp each render/run of this script with a UUID, and add log/<method>/<UUID> dirs
TODO: according to ?system, system2() is better, so switch to that eventually I guess. More portable. 
TODO: replace all the "r"s or "c"s with "i"s or "j"s in apply functions like mapply(1:nrow(x), 1:ncol(x), function(r,c) {...})

# Lib
```{r}
#| output: false
library(data.table)
library(SeqArray)
library(SNPRelate)
```
```{r}
"%ni%" <- Negate("%in%")
```

# Configs
```{r}
misc_config <- list()
              source("config/config.misc")
data_config <- fread("config/config.data")
loci_config <- fread("config/config.loci.all")
anno_config <- fread("config/config.anno")
```
TODO: printout "stamp" of configs s.t. in the rendered doc, it is clear what was run.

## Validate input
```{r}
# TODO: Why? Because the rest of the code is cleaner under the assumption all input datasets are valid, and error messages early save the user time.
  # data
    # Make sure the data files exist (and maybe check if they're valid too? Can use fread(...,nrows=3) to quickly peek)
    # Make sure all cols required by all misc_config$fm_methods is there are specified for every data file
    # Make sure valid reference genomes
    # Make sure every dataset's ancestry is a valid ancestry in the reference panel too
      # Make sure the script is robust to whether these ancestry names are capitalized or not
  # loci: make sure valid reference genomes
  # anno
    # Make sure no "+"s in anno names b/c will mess w/ fgwas.
    # Check anno files all exist (and are proper bed format too? nah)
  # misc
    # Check valid reference panel
      # Check data integreity (checksums)
if(misc_config$ref_panel %ni% c("1kG", "gnomAD_1kG+HGDP")) stop(paste0("Invalid reference panel: ", misc_config$ref_panel, ". Please correct this in config.misc."))
# if(any(misc_config$gnomad_eur_ancestries %ni% c("nfe", "fin", "asj")) || length(misc_config$gnomad_eur_ancestries)==0) stop(paste0("")) # TODO:
if(!dir.exists(misc_config$scratch_dir)) stop(paste0("Scratch directory ", misc_config$scratch_dir, " does not exist. Please create it, or change your desired scratch directory in config.misc."))
```
```{r}
if(misc_config$ref_panel == "1kG"   ) misc_config$ref_panel_ref_genome <- "hg19"
if(misc_config$ref_panel == "gnomAD_1kG+HGDP") misc_config$ref_panel_ref_genome <- "hg38"
```

## `liftOver` loci and annotations
More efficient and accurate to `liftOver` `config.loci`/`.anno` to the sumstats' reference genomes rather than vice-versa. The summary stats are likely big files, especially before we have had the chance to subset them to only the necessary variants.\
In addition, it is not recommended (source [1](http://genome.ucsc.edu/FAQ/FAQreleases.html#snpConversion), [2](https://groups.google.com/a/soe.ucsc.edu/g/genome/c/wkgf5DXpwEc/m/wDpsjyDVCQAJ)) to `liftOver` individual variants by their position — converting position via rsID is more accurate.\
That said, even rsIDs can be ambiguous ([source](https://gnomad.broadinstitute.org/help/why-is-this-variant-linked-to-the-wrong-dbsnp-rsid)), so it's better to avoid `lift`ing`Over` the sumstats if possible.\
TODO add blurb about how b37 hg19 CRCh37 are mostly equiv except mitochondria and "chr#" vs "#" and link sources, and how GRCh38 and hg38 are equiv AFAIK

### Convert to UCSC naming scheme
`liftOver` uses the UCSC naming scheme, we need to too.
```{r}
#| output: false
lapply(list(data_config, loci_config, anno_config), function(config_file) {
  config_file[ref_genome %in% c("GRCh37", "b37", "hg19"), ref_genome := "hg19"]
  config_file[ref_genome %in% c("GRCh38",        "hg38"), ref_genome := "hg38"]
  config_file[, ref_genome := factor(ref_genome)]
})
```

### `liftOver`
```{r}
if(!dir.exists("out/liftover")) dir.create("out/liftover", recursive=T)
source("inc/liftOver.R")

loci_configs <-
lapply(union(data_config$ref_genome, misc_config$ref_panel_ref_genome), function(dg) {
  loci_config_bed_format <- data.table(
    chrom      = {if(!grepl("chr",loci_config$chr[1])) paste0("chr",loci_config$chr)
                  else                                              loci_config$chr },
    chromStart = loci_config$pos_min,
    chromEnd   = loci_config$pos_max,
    name       = loci_config$locus
  )

  loci_config_lifted <- do.call(rbind,
  lapply(unique(loci_config$ref_genome), function(lg) {
    loci_of_a_ref_genome_bed <- loci_config_bed_format[loci_config$ref_genome == lg] 
    if(dg != lg)
      liftOver("third_party/liftover/liftOver",
               loci_of_a_ref_genome_bed,
               from_build = lg, to_build = dg)
    else
      loci_of_a_ref_genome_bed
  })
  )

  setnames(setDT(loci_config_lifted), c("chr","pos_min","pos_max","locus"))
  loci_config_lifted[, chr := sub("chr","",chr)] # Undo UCSC chr naming # TODO: make factor, and make a convenience chrFactor() function to use here and when reading sumstats?

  fwrite(loci_config_lifted, paste0("out/liftover/config.loci.",dg), sep=' ')
  loci_config_lifted
})
names(loci_configs) <- union(data_config$ref_genome, misc_config$ref_panel_ref_genome)

anno_configs <- 
lapply(unique(data_config$ref_genome), function(dg) {
  lifted_anno_config <- copy(anno_config)
  sapply(1:nrow(anno_config), function(i) {
    ag <- anno_config[i,ref_genome]
    if(dg != ag) {
      lifted_bed_file <- paste0("out/liftover/",anno_config[i,name],"-lifted_to_",dg,".bed")
      liftOver("third_party/liftover/liftOver",
               anno_config[i,bed_file],
               out_file = lifted_bed_file, 
               from_build = ag, to_build = dg)

      lifted_anno_config[i, `:=`(ref_genome = dg,
                                 bed_file = lifted_bed_file)]
    }
  })
  fwrite(lifted_anno_config, paste0("out/liftover/config.anno.",dg), sep=' ')
  lifted_anno_config
})
names(anno_configs) <- unique(data_config$ref_genome)
```

# GWAS summary stats
```{r}
#| output: false
sumstats <- lapply(1:nrow(data_config), function(r) {
  loci <- loci_configs[[ data_config[r,ref_genome] ]] # Loci with coords lifted to the current data file's ref genome

  # AWK command given to fread(). Filters variants not in any config.loci locus, or with EAF of 0 or 1.
  # If your data is huge but you only care to look at a few regions, this saves memory.
  chr_pos_eaf_preprocess_cmd <- paste0(
    "awk ",
    "-v chrs_string='",paste(collapse=' ', loci$chr),     "' ",
    "-v mins_string='",paste(collapse=' ', loci$pos_min), "' ",
    "-v maxs_string='",paste(collapse=' ', loci$pos_max), "' ",
    "'BEGIN {",
      "getline; print;", # Get header line
      # Turn the space-delimited strings into arrays
      "split(chrs_string, chrs, \" \");",
      "split(mins_string, mins, \" \");",
      "split(maxs_string, maxs, \" \");",
    "}",
    "{",
      "for(i=0; i<=",nrow(loci),"; i++) {",
        "if($",data_config[r,chr_col]," == chrs[i] && ",
           "$",data_config[r,pos_col]," >= mins[i] && ",
           "$",data_config[r,pos_col]," <= maxs[i]) { ",
           "print; break;",
        "}",
      "}",
    "}' ",
    data_config[r,filepath]
  )

  sumstat <- data_config[r, fread(cmd = chr_pos_eaf_preprocess_cmd,
                                   select=c(chr_col, pos_col, rsid_col, other_allele_col, effect_allele_col, eaf_col, b_col, se_col, z_col, p_col, n_col))]
  unspecified_cols <- is.na(data_config[r,.(chr_col, pos_col, rsid_col, other_allele_col, effect_allele_col, eaf_col, b_col, se_col, z_col, p_col, n_col)])
  setnames(sumstat,                      c("chr",   "pos",   "rsid",   "a0",             "a1",              "eaf",   "b",   "se",   "z",   "p",   "n")[!unspecified_cols])

  sumstat[,chr := factor(chr,levels=c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","X","Y","M"))] # TODO: make sure things will line up correctly even if user uses UCSC "chr#" naming or not.
  sumstat[,`:=`(a0=toupper(a0), a1=toupper(a1))]
  if("eaf" %in% names(sumstat)) sumstat <- sumstat[eaf > 0 & eaf < 1]

  # Infer some columns from the others if possible. For example, z-score can be calculated from β and SE.
  if(data_config[r, is.na(z_col) & !is.na(b_col) & !is.na(se_col)]) sumstat[, z := b/se]
  # TODO: possible to reverse-engineer N from p/z/se/af if n_col not given?

  sumstat
})
names(sumstats) <- basename(data_config$filepath)
```

TODO: make automatic which reference panels' code runs based on misc\_config$ref\_panel
TODO TODO TODO: unify code for 1kG and gnomAD getting VCFs from the internet and merging
  Adding sample info will be different though.
  gnomAD filter might be different. (I think both have a variant FILTER, but gnomAD also has an additional sample filter high_quality)
  Also consider if the user were to provide their own VCF file, possibly with separate sample info

# Reference panel
## 1kG
### Load
```{r}
#| output: false
ref <- seqOpen("../data/ref/1kg/gds_format/1KG_ALL.autosomes.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.gds", readonly=F, allow.duplicate=T)

# Add sample info to the GDS file
sample_info <- fread("../data/ref/1kg/sample_info/integrated_call_samples_v3.20130502.ALL.panel")
stopifnot(identical(seqGetData(ref,"sample.id"), sample_info$sample))
seqAddValue(ref, "sample.annotation/ancestry", sample_info$super_pop, replace=T)
seqAddValue(ref, "sample.annotation/gender", sample_info$gender, replace=T)
```

### Filter sumstats using ref panel (1kG)
First, filter out useless/unusable variants from the summary stats: \
1. If variant's ancestry-specific MAF is 0 for that sumstat file's ancestry
2. If variant is not within the bounds of any loci specified in `locus.config`
3. If variant not also present in reference panel
```{r}
#| output: false
seqSetFilterChrom(ref, loci_configs$hg19$chr,
               from.bp=loci_configs$hg19$pos_min,
                 to.bp=loci_configs$hg19$pos_max)

samples_of_each_ancestry <- tapply(seqGetData(ref,"sample.id"), INDEX=seqGetData(ref,"sample.annotation/ancestry"), FUN = identity) 
ancestries_MAFs <- lapply(samples_of_each_ancestry, function(samples_of_an_ancestry) {
    seqSetFilter(ref, sample.id = samples_of_an_ancestry)
    seqAlleleFreq(ref, minor=T)
}) 
seqResetFilter(ref, variant=F)

invisible(sapply(data_config$ancestry, function(anc) if(anc %ni% names(ancestries_MAFs)) { print(paste("ERROR: Ancestry",anc,"mentioned in config.data is not an ancestry in the reference panel:", paste(collapse=", ", names(ancestries_MAFs)), "\nPlease remove this dataset from config.data, or if this was just a typo, change the ancestry name to match one of those in the reference panel.")); stop() })) # TODO: this belongs earlier, when loading in the data. But a nice sanity check to have for now.

sumstats <- mapply(sumstats, data_config$ancestry, SIMPLIFY=F,
  FUN = function(s, anc) {
    ancestry_MAFs <- ancestries_MAFs[[anc]]
    seqSetFilter(ref, action = "push+intersect", variant.sel = ancestry_MAFs > misc_config$maf_threshold)

    s <- s[rsid %in% seqGetData(ref,"annotation/id")]
    seqFilterPop(ref)
    s
})
#save(sumstats, samples_of_each_ancestry, file="filtered_sumstats.RData")
```

# WIP
## Get from internet
```{r}
{
if(misc_config$ref_panel == "1kG")
  ref_panel_files <- paste0("http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr",1:22,".phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz") 
else if(misc_config$ref_panel == "gnomAD_1kG+HGDP")
  ref_panel_files <- paste("gs://gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.hgdp_tgp.chr",1:22,".vcf.bgz")
else
  ref_panel_files <- misc_config$ref_panel # TODO: allow user to provide their own. Everything *should* mostly already work for this, but I need to test.
}

lc <- loci_configs[[misc_config$ref_panel_ref_genome]]
regions_bed_format <- data.table(chrom = lc$chr, chromStart = lc$pos_min, chromEnd = lc$pos_max)

source("inc/Vcfs2Gds.R")
ref_gds <-
Vcfs2Gds(ref_panel_files, 
         output_name = paste0(misc_config$scratch_dir,"/ref_panel.gds"),
         variant_ids = Reduce(union, lapply(sumstats, '[', j=rsid)),
         regions = regions_bed_format)
# TODO: stamp the filename with something unique, probably.
# TODO: as mentioned here: https://www.biostars.org/p/299110/ and https://www.biostars.org/p/119295/#119308
  # Chrs can have all sorts of wacky formats, not just "chr#" vs. "#" problems. So add a map.file argument to Vcfs2Gds? But then again the user might also provide a GDS.
  # Where should the chromosome naming harmonization stuff go??? It's very annoying. Having the user worry about a map.file would also be annoying for them.
ref <- seqOpen(ref_gds)

# TODO: now to add sample info and stuff.
```

## gnomAD 1kG + HGDP subset
### Get necssary data from internet
```{r}
# TODO: move this code chunk to separate file, then wrap that in an if( ! already_exists)
# TODO: paste0(misc_config$scratch_dir...) filenames too wordy, predefine them or s/t to be more concise and avoid bugs
all_rsids <- Reduce(union, lapply(sumstats, '[', j=rsid))
all_rsids_file <- paste0(misc_config$scratch_dir,"/all_rsids.txt")
writeLines(all_rsids, all_rsids_file)

lapply(1:nrow(loci_config), function(i) {
  loci <- loci_configs[[misc_config$ref_panel_ref_genome]]

  l_vcf <- paste0(misc_config$scratch_dir,"/",loci[i,locus],"_gnomad.vcf")
  l_gds <- paste0(misc_config$scratch_dir,"/",loci[i,locus],"_gnomad.gds")

  # TODO: only take the INFO fields I need.
    # IMPORTANT! Easy thing that's really worth doing before scaling up to more loci.
    # If bcftools supports this do it here. Otherwise use the seqVCF2GDS info.import field.
  loci[i, system(paste0( "bcftools view",
                         " -r chr",chr,":",pos_min,"-",pos_max,   # TODO: hardcoded again to use "chr#" which is what gnomAD uses; the problem is this code assumes that loci_config uses just "#" which I might change again later
                         " -i ID==@",all_rsids_file,
                         " gs://gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.hgdp_tgp.chr",chr,".vcf.bgz",
                         " > ", l_vcf ))]

  # TODO: use parallel=<> param for more speed
  seqVCF2GDS(l_vcf, l_gds, storage.option="ZIP_RA", digest=F) # See ?seqRecompress: VCF2GDS conversion takes tons of memory w/ default compression. Better to use lower compression during conversion, then use seqRecompress() after. No checksum digest b/c I'm a gangsta, totally not b/c I'm impatient
  #seqRecompress(    l_gds,               "ZIP_RA") # TODO: Could also use LZ4 b/c is fast, but what if data is huge? Let user choose.
  unlink(l_vcf)
})

unlink("*.tbi") # Tabix index files clutter the working directory when you access VCF files over the internet, remove these. 
unlink(all_rsids_file)

# TODO: stamp final gds filename w/ UUID or s/t.
     seqMerge(paste0(misc_config$scratch_dir,"/",loci_config$locus,"_gnomad.gds"), paste0(misc_config$scratch_dir,"/gnomad.gds"), storage.option="ZIP_RA", digest=F)
seqRecompress(paste0(misc_config$scratch_dir,"/gnomad.gds"),"LZMA")
       unlink(paste0(misc_config$scratch_dir,"/",loci_config$locus,"_gnomad.gds"))
```

### Load
```{r}
ref <- seqOpen(paste0(misc_config$scratch_dir,"/gnomad.gds"), readonly=F)

{ # Add sample info to the GDS file.
sample_info <- fread("../data/ref/gnomad_1kg+hgdp/sample_info/gnomad.genomes.v3.1.2.hgdp_1kg_subset_sample_meta.tsv")
sample_info$pop <- sapply(sample_info$gnomad_population_inference, function(x) ifelse(is.na(x), NA, jsonlite::fromJSON(x)$pop))
sample_info <- sample_info[match(seqGetData(ref,"sample.id"), s)]

identical(sample_info$s, seqGetData(ref,"sample.id"))

seqAddValue(ref, "sample.annotation/ancestry", sample_info$pop, replace=T)
high_quality <- sample_info$high_quality
high_quality[is.na(high_quality)] <- FALSE # TODO: make cleaner (how?) It's just the first sample that is NA.
seqAddValue(ref, "sample.annotation/high_quality", high_quality, replace=T) # Filter recommended by gnomAD, see https://gnomad.broadinstitute.org/news/2021-10-gnomad-v3-1-2-minor-release/
}
```

### Filter sumstats using ref panel (gnomAD 1kG + HGDP subset)
```{r}
seqSetFilterChrom(ref, loci_configs$hg38$chr, # Already got only the necessary variants from the internet, but just for clarity
               from.bp=loci_configs$hg38$pos_min,
                 to.bp=loci_configs$hg38$pos_max)
seqSetFilter(ref, action="push+intersect", variant.sel = seqGetData(ref, "annotation/filter")=="PASS")
seqSetFilter(ref, action="push+intersect",  sample.sel = seqGetData(ref, "sample.annotation/high_quality"))
seqFilterPush(ref) # The above filters will remain on everything else we do from now on.

samples_of_each_ancestry <- tapply(seqGetData(ref,"sample.id"), INDEX=seqGetData(ref,"sample.annotation/ancestry"), FUN = identity) 
# Should Finnish be included in the European ancestry group? Decided by config.misc.
if(misc_config$gnomad_count_fin_as_eur) { samples_of_each_ancestry$eur <- union(samples_of_each_ancestry$nfe, samples_of_each_ancestry$fin)
} else                                  { samples_of_each_ancestry$eur <-       samples_of_each_ancestry$nfe                               }

ancestries_MAFs <- lapply(samples_of_each_ancestry, function(samples_of_an_ancestry) {
    seqSetFilter(ref, action="push+intersect", sample.id = samples_of_an_ancestry)
    af <- seqAlleleFreq(ref, minor=T)
    seqFilterPop(ref)
    af
}) 

sumstats <- mapply(sumstats, data_config$ancestry, SIMPLIFY=F, FUN = function(s, anc) {
    anc <- tolower(anc)
    ancestry_MAFs <- ancestries_MAFs[[anc]]
    seqSetFilter(ref, action="push+intersect", variant.sel = ancestry_MAFs > misc_config$maf_threshold)

    s <- s[rsid %in% seqGetData(ref,"annotation/id")]
    seqFilterPop(ref)
    s
})
```

# Annotation
## Add Annotation Columns
```{r}
# TODO: PAINTOR's script is fast, but would be more elegant to do in R than system calls to Python
anno_colss <- mapply(sumstats, 1:length(sumstats), SIMPLIFY=F, FUN = function(sumstat,i) {
  scratch_dir <- misc_config$scratch_dir
  sumstat$chr <- paste0("chr",sumstat$chr)
  fwrite(sumstat[, .(chr,pos)], paste0(scratch_dir,"/sumstat",i), sep=' ')

  writeLines(anno_config$bed_file, paste0(scratch_dir,"/config.anno.tmp"))

  # TODO: put this virtualenv cruft in misc$scratch_dir at least, if you're going to keep using PAINTOR's script 
  if(!dir.exists("py_env")) system("virtualenv py_env; source py_env/bin/activate; python -m pip install numpy")
  system(paste0("source py_env/bin/activate; python3 ../third_party/PAINTOR_V3.0/PAINTOR_Utilities/AnnotateLocus.py -o ",scratch_dir,"/anno_cols.txt -c chr -p pos -i ",scratch_dir,"/config.anno.tmp -l ",scratch_dir,"/sumstat",i))

  anno_cols <- fread(paste0(scratch_dir,"/anno_cols.txt"))
  names(anno_cols) <- anno_config$name

  unlink("config.anno.tmp")
  unlink(paste0(scratch_dir,"/anno_cols.txt"))
  unlink(paste0(scratch_dir,"/sumstat",i))
  anno_cols 
})
lapply(anno_colss,lapply,sum) # Make sure everything isn't just 0
sumstats <- mapply(sumstats, anno_colss, SIMPLIFY=F, FUN=cbind)
```

## Add `SEGNUMBER` and `locus` Columns
```{r}
lapply(sumstats, function(s) {
  s[,locus := factor(levels=loci_config$locus)]
  lapply(1:nrow(loci_config), function(l) {
    s[ chr == loci_config$chr[l] &
       pos >= loci_config$pos_min[l] &
       pos <= loci_config$pos_max[l],
       `:=`(locus=l, SEGNUMBER=l)       ]
})})
```

### fgwas
```{r}
if(!dir.exists("in/fgwas")) dir.create("in/fgwas")
if(!dir.exists("out/fgwas")) dir.create("out/fgwas")

# Functions here assume sumstat_file is formatted properly for fgwas -fine. I.e.:
  # has "SNPID", "CHR", "POS", "Z", "F", "N", "SE", "SEGNUMBER", and anno cols.
    # CHR must named "chr#" not just "#".
    # F and N can be blank as they are overridden by SE, but must be present nonetheless for some reason.
    # Sorted by SEGNUMBER,CHR,POS

# Iteratively adds the anno which most increases the model's likelihood, until no more improvement. 
fgwasGetBestLikelihoodAnnos <- function(sumstat_file, annos_to_try, annos_acc, best_llk) {

  llks <- sapply(annos_to_try, function(anno) { # TODO: embarassingly parallel lapply
    fgwas_out_prefix <- paste0("out/fgwas/",anno_to_try,"-",sumstat_file)

    model <- paste(collapse='+',c(annos_acc, anno_to_try));    if(length(annos_acc)==0) model <- anno_to_try
    system(paste0("../third_party/fgwas/src/fgwas -fine",
                  " -i ", sumstat_file,
                  " -w ", model, 
                  " -o ", fgwas_out_prefix))

    llk <- fread(paste0(fgwas_out_prefix,".llk"))[1,2]
  })
 
  if(max(llks) > best_llk) {
    new_best_llk <- max(llks)
    anno_to_add  <- names(llks)[which.max(llks)]
    new_anno_acc <- c(anno_acc, anno_to_add)

    return(fgwasGetBestLikelihoodAnnos(sumstat_filename, annos_to_try[!anno_to_add], new_anno_acc, new_best_llk) )
  } else return(anno_acc)
}
# The above function is recursive.
# tailr::loop_transform makes it slightly faster and makes sure it doesn't overflow the stack, because R doesn't implement tail recursion.
  # (Tail recursion is when you don't need to hold all recursive calls in memory if your recursive function returns only a call to itself or a final value.)
fgwasGetBestLikelihoodAnnos <- tailr::loop_transform(fgwasGetBestLikelihoodAnnos)

# Tests which penalty value has the best cross-validation likelihood, given the model fgwasGetBestLikelihoodModel()
fgwasGetBestXValidationPenalty <- function(sumstat_file, annos) {
  # TODO: Does f(model,penalty) have only one minimum? If so, could optimize by making more intelligent choices of penalty. 
  # TODO: Go finer than steps of 0.05?
  penalties <- seq(0, 1, 0.05)

  xv_llks <- lapply(penalties, function(penalty) { # TODO: embarassingly parallel lapply
    fgwas_out_prefix <- paste0("out/fgwas/",as.character(penalty),"-",sumstat_file)

    model <- paste(collapse='+', annos)
    system(paste0( "../third_party/fgwas/src/fgwas -fine -xv -print",
                   " -i ", sumstat_file,
                   " -w ", model, 
                   " -p ", penalty,
                   " -o ", fgwas_out_prefix))

    a <- fread(paste0(fgwas_out_prefix,".ridgeparams"))
    xv_llk <- a[,nrow(a)] # Kinda wack, but fgwas puts the x-validation likelihood result in the last line of the .ridgeparams output files.
  })

  return(list(
    best_xv_llk = max(xv_llks),
    best_penalty = penalties[which.max(xv_llks)]
  ))
}

# Iteratively drops annos from the model, until the cross-validation likelihood is maximized.
fgwasGetBestXValidatedAnnos <- function(sumstat_file, xv_penalty, annos, best_xv_llk) {
  # TODO: Here I assume that dropping an anno in the middle of the model *might* cause an anno earlier in the model to now also increase the llk if dropped, even if that wasn't the case before dropping the middle anno.
    # This might be overly cautious, in which case, this could be optimized by only needing to traverse the model once, dropping whatever increases the llk without having to look back.
  xv_llks <- sapply(annos, function(anno_to_drop) { # TODO: embarassingly parallel lapply
    fgwas_out_prefix <- paste0("out/fgwas/drop_",anno_to_drop,"-",sumstat_file)

    model <- paste(collapse='+', annos[!anno_to_drop])
    system(paste0( "../third_party/fgwas/src/fgwas -fine -xv -print",
                   " -i ", sumstat_file,
                   " -w ", model,
                   " -p ", penalty,
                   " -o ", fgwas_out_prefix))

    a <- fread(paste0(fgwas_out_prefix,".ridgeparams"))
    xv_llk <- a[,nrow(a)]
  })

  best_new_xv_llk <- max(xv_llks)
  if(max(xv_llks) > best_xv_llk) {
    new_best_xv_llk <- max(xv_llks)
    anno_to_drop <- names(xv_llks)[which.max(xv_llks)]
    new_annos <- annos[!anno_to_drop]

    return(fgwasGetBestXValidatedAnnos(sumstat_file, xv_penalty, new_annos, new_best_xv_llk))
  } else return(annos)

}
fgwasGetBestXValidatedAnnos <- tailr::loop_transform(fgwasGetBestXValidatedAnnos)


# Takes the sumstats, formats them in a way fgwas likes, then applies the above functions to get the annotations of the best-likelihood model.
best_annos <- 
lapply(sumstats, function(s) { # TODO: embarassingly parallel lapply
  s <- s[, .SD, .SDcols=c( "rsid","chr","pos","z","se","SEGNUMBER",anno_config$name)]
  setnames(s,           c("SNPID","CHR","POS","Z","SE","SEGNUMBER",anno_config$name))
                                   # fgwas requires specific header names.
  s <- s[order(SEGNUMBER,CHR,POS)] # fgwas requires ordering by SEGNUMBER (if -fine option), and chr and pos.
  s[,chr := paste0("chr",CHR)]     # fgwas uses hg19 "chr#" syntax, not just the number.
  s[,`:=`(F=0, N=0)]               # fgwas errors if missing F or N col, even though overridden by SE.

  input_filename <- paste0("in/fgwas/",s_nm,"-fgwas.gz")
  fwrite(s, input_filename, sep=' ', compress="gzip")

  # Old, to test just one anno at a time, use me instead of the below code. # TODO: rm me eventually
  #lapply(anno_config$name, function(anno) {
  #  system(paste0( "../third_party/fgwas/src/fgwas -i ", input_filename, " -fine",
  #                 " -w ", anno,
  #                 " -o out/fgwas/",s_nm,"-",anno ))
  #})

  annos   <- fgwasGetBestLikelihoodAnnos(input_filename, anno_config$name, c(), 0)
  l       <- fgwasGetBestXValidationPenalty(input_filename, annos)
  return(    fgwasGetBestXValidatedAnnos(input_filename, annos, l$best_penalty, l$best_xv_llk))
})
```

## Subset
Split the summary stats into sets of subsets, one per locus.
```{r}
sumstats <- lapply(sumstats, '[', order(rsid)) # Things remain sorted after subsetting.
subset_sumstatss <- lapply(1:nrow(loci_config), function(r) {
                    mapply(sumstats, data_config$ref_genome, SIMPLIFY=F, FUN = function(s, ref_genome) {

  s[ chr == loci_configs[[ref_genome]][r,chr]     &
     pos >= loci_configs[[ref_genome]][r,pos_min] &
     pos <= loci_configs[[ref_genome]][r,pos_max] ]
})})
names(subset_sumstatss) <- loci_config$locus
```

# LD
Calculate LD per ancestry per locus.\
This is more space-efficient than calculating LD per dataset per locus, assuming the datasets have most of their variants in common (which they should!—or else what is the point of multi-dataset finemapping?).
```{r}
# TODO: consider: generating subsets of sumstats and holding them all in memory? Or just holding the rsids necessary to subset each sumstat _later on_?
  # Could actualy be more concise to have just the rsids and subset as I go.

# Signed Pearson r.
# Returned LD matrix's rows/cols are sorted to match the order of the given rs_ids.
# Filters on the GDS file ~are~ taken into account. The GDS file will be returned with the same filters as before.
ldCalc <- function(gds_file, rs_ids, sample_ids=NULL, ref_alleles=NULL, outfile_name=NULL, n_threads=parallel::detectCores()) {
  if(is.null(ref_alleles)) warning("calc_ld() warning: specifying your data's ref_alleles is highly recommended! If the reference alleles (i.e. non-effect alleles) in your data =/= those in the reference panel, the LD will be incorrect.")
  seqFilterPush(gds_file) # Save user's prexisting filter on the file if they have one

  seqSetFilterAnnotID(gds_file, rs_ids)
  if(!is.null(sample_ids)) seqSetFilter(gds_file, sample.id = sample_ids, action="intersect")

  tmp_filename <- "/tmp/snpgds_format_file.gds"
  seqGDS2SNP(gds_file, tmp_filename, compress.geno="", compress.annotation="")
  tmp <- snpgdsOpen(tmp_filename, readonly=F)
  #print(paste(identical(read.gdsn(index.gdsn(tmp,"snp.rs.id")), seqGetData(gds_file,"annotation/id")))) # TRUE

  # Sort user-given ref_alleles to match the order of the GDS file before allele switching!
  # Why not sort the GDS file to match user input instead? B/c raw data files should not be edited.
  ref_alleles <- ref_alleles[match(seqGetData(gds_file,"annotation/id"), rs_ids)]
  snpgdsAlleleSwitch(tmp, toupper(ref_alleles))
  ld <- snpgdsLDMat(tmp, slide=0, method="corr", num.thread=n_threads)$LD

  snpgdsClose(tmp) # Don't need SNP GDS format file anymore
  unlink(tmp_filename)

  # Sort LD matrix to match the order of the user-given rs_ids.
  rs_ids_order <- match(rs_ids, seqGetData(gds_file,"annotation/id"))
  ld <- ld[rs_ids_order, rs_ids_order]

  if(!is.null(outfile_name)) {
    if(!dir.exists(dirname(outfile_name))) dir.create(dirname(outfile_name), recursive=T)
    fwrite(ld, outfile_name, sep=' ', col.names=F, compress="gzip")
  }

  seqFilterPop(gds_file) # Set filter to however it was before
  ld
}
# Note: it doesn't (and shouldn't!) matter that the seqSetFilterChrom filter from before is still active.

ld_rsid_orders <-
  sapply(       loci_config$locus,     simplify=F, function(l) {
  sapply(unique(data_config$ancestry), simplify=F, function(anc) {
    samples_of_an_ancestry <- samples_of_each_ancestry[[anc]]
    sumstats_of_an_ancestry <- subset_sumstatss[[l]][which(data_config$ancestry == anc)]
    common_rsids_in_sumstats_of_an_ancestry <- Reduce(union, lapply(sumstats_of_an_ancestry, '[', j=rsid))

    # TODO: not generalizable if multiple datasets in an ancestry with different rsids and/or different effect alleles.
      # Simple solution would be in data pre-proc: just flip alleles & β & z & etc..
      # For now w/ just the DIAMANTE data w/ one dataset per ancestry it's fine. Even the different ancestries have matching a0/a1, I checked.
    a_sumstat_of_an_ancestry <- sumstats_of_an_ancestry[[1]][rsid %in% common_rsids_in_sumstats_of_an_ancestry]
    #print(paste(identical(a_sumstat_of_an_ancestry$rsid, common_rsids_in_sumstats_of_an_ancestry)))
    ref_alleles <- a_sumstat_of_an_ancestry$a0

    ldCalc(ref, rs_ids = common_rsids_in_sumstats_of_an_ancestry,
             sample_ids = samples_of_an_ancestry,
            ref_alleles = ref_alleles,
           outfile_name = paste0("in/ld/",l,"-",anc,".ld.gz"),
              n_threads = 6L) 
  
    common_rsids_in_sumstats_of_an_ancestry # Return the order of the LD mat's rows/cols, important!
})})

save(ld_rsid_orders, file="in/ld/ld_rsid_orders.RData") # TODO: Save as separate files, with one col of just rsids? This way, LD could be used by non-R programs more easily.
```

# Run Fine-Mapping Methods
## SuSiEx
### Prep Input
SuSiEx is a command-line python program. It expects the following:\
A summary stats file, as follows:\ 
TODO: make nice table\
The β column _must_ be named "BETA" or "OR", but besides that they may be named arbitrarily.
```{r}
if(!dir.exists("in/susiex")) dir.create("in/susiex")
# TODO: ensure data contains the required columns
lapply(loci_config$locus, function(l) {
mapply(subset_sumstatss[[l]], names(sumstats), FUN=function(s, nm) {
  s <- s[, .(chr,pos,rsid,a0,a1,b,se,p)]
  setnames(s, old="b", new="BETA", skip_absent=T)
  fwrite(s, paste0("in/susiex/",l,"-",nm), sep='\t')
})})
```

```{r}
# TODO: PLINK stuff :(
  # NOTE TO SELF: see daily note 230605. Letting SuSiEx recompute its own LD for now just to get things working.
```

### Run SuSiEx
```{r}
if(!dir.exists("out/susiex")) dir.create("out/susiex", recursive=T)
err <- lapply(1:nrow(loci_config), function(r) {
  system(paste("../third_party/SuSiEx/bin/SuSiEx",
               "--sst_file", paste(collapse=',', paste0("in/susiex/",loci_config[r,locus],"-",names(sumstats))),
               "--n_gwas",   paste(collapse=',', data_config$n),
               "--ld_file",  paste(collapse=',', paste0("in/ld/",loci_config[r,locus],"-",unique(data_config$ancestry),"-susiex")), # TODO: compute own LD
               "--ref_file ../data/ref/1kg/plink_format/eas/g1000_eas,../data/ref/1kg/plink_format/eur/g1000_eur,../data/ref/1kg/plink_format/sas/g1000_sas", # TODO:
               "--plink plink", # TODO:
               "--out_dir out/susiex",
               "--out_name", loci_config[r,locus],
               #"--level 0.95", # Default
               "--chr ", loci_config[r,chr],
               "--bp ", paste(sep=',', loci_config[r,pos_min], loci_config[r,pos_max]),
               "--chr_col", paste(collapse=',', rep(1,nrow(data_config))),
               "--bp_col",  paste(collapse=',', rep(2,nrow(data_config))),
               "--snp_col", paste(collapse=',', rep(3,nrow(data_config))),
               "--a1_col",  paste(collapse=',', rep(4,nrow(data_config))),
               "--a2_col",  paste(collapse=',', rep(5,nrow(data_config))),
               "--eff_col", paste(collapse=',', rep(6,nrow(data_config))),
               "--se_col",  paste(collapse=',', rep(7,nrow(data_config))),
               "--pval_col",paste(collapse=',', rep(8,nrow(data_config))),
               "--maf", misc_config$maf_threshold, # TODO: 0 is not allowed, why?
               #"--min_purity 0.5", # Default. Even if some credsets are impure and not practically useful, still want all the posteriors for comparison purposes. TODO: Purity filter of 0 causes errors for some loci, see daily note 230621. 0.01 is totally low enough but it not being 0 still bothering me. Low priorty to look into.
               "--mult-step True",
               "--keep-ambig True",
               "--threads", 6L # TODO: make more general, or allow input
               # defaults: --max_iter=100, --pval_thresh=1e-5, --tol=1e-4, --n_sig=5
  ))
})
# TODO: use "err" to print a warning if SuSiEx fails for some loci, and specify the loci.
```

## PAINTOR
### Prep Input
PAINTOR only works on variants shared by ALL input datasets.\
TODO: desc
```{r}
if(!dir.exists("in/paintor")) dir.create("in/paintor")
# input.files
writeLines(loci_config$locus, "in/paintor/input.files")

# Locus files. Format:
# rsid  pop1_z  pop2_z ...
#  rs1   -3.14  -1.337
#  ... <no NAs allowed>
desired_rsidss <- sapply(loci_config$locus, simplify=F, function(l) {
  signif_rsids <- Reduce(union,     lapply(subset_sumstatss[[l]], '[', j=rsid)) # NOTE: optional hardcoded p threshold here
  common_rsids <- Reduce(intersect, lapply(subset_sumstatss[[l]], '[',           j=rsid))
  desired_rsids <- intersect(signif_rsids, common_rsids)
})

lapply(loci_config$locus, function(l) {
  desired_rsids <- desired_rsidss[[l]]
  desired_sumstats <- lapply(subset_sumstatss[[l]], function(s) s[rsid %in% desired_rsids]) # We sorted before, so all sumstats' rsids are in the same order even after subsetting. 

  paintor_locus_file <- Reduce(cbind, lapply(desired_sumstats, '[', j=z), desired_rsids) # Can add more metadata than just rsid if you want
  colnames(paintor_locus_file) <- c("rsid", paste0(names(sumstats),"_z"))
  fwrite(paintor_locus_file, paste0("in/paintor/",l), sep=' ')
})

# LD files. Format: Pearson r, space-delim'd, no header, Must have same number of rows and order as locus file.
lapply(loci_config$locus, function(l) {
  desired_rsids <- desired_rsidss[[l]]
  ld_filenames <- paste0("in/ld/",l,"-",unique(data_config$ancestry),".ld.gz")
  desired_filenames <- paste0("in/paintor/",l,".ld_",unique(data_config$ancestry))
  lds <- lapply(ld_filenames, function(f) as.matrix(fread(f)))
  mapply(lds, ld_rsid_orders[[l]], desired_filenames, SIMPLIFY=F, FUN = function(ld, ld_rsid_order, nm) {
    # return(c(length(ld_rsid_order),length(desired_rsids), sum(ld_rsid_order %in% desired_rsids)))
    # TODO: This code could definitely be made clearer.
    desired_subset <- ld_rsid_order %in% desired_rsids # TODO: rename ld_rsid_order variable to not "order". Because it's just rsids.
    ld <- ld[desired_subset, desired_subset]
    ld_rsid_order <- ld_rsid_order[desired_subset]

    desired_order <- match(desired_rsids, ld_rsid_order)
    ld <- ld[desired_order,desired_order]

    fwrite(ld, nm, sep=' ', col.names=F)
  })
}) # TODO: A more elegant way? Unfortunately PAINTOR insists having all its input files in a single dir, so that means either cluttering in/ld/, changing filesnames in in/ld/ to use weird naming conventions, or making copies.... And PAINTOR doesn't accept compression so copies it is I guess....
# AND it wants to take in all loci at once, which means you have to store ALL the (decompressed!) LD files at once w/o being able to delete them as you go.

# Annotation files. Format:
# annot1  annot2 ...
# 0 or 1  0 or 1 
# Must have same number of rows and order as locus file.
# TODO: dummy all-0s file for now
lapply(loci_config$locus, function(l) {
  desired_rsids <- desired_rsidss[[l]]
  writeLines(c("dummy_annot", rep(0,length(desired_rsids))),
             paste0("in/paintor/",l,".annotations"))
})
```

### Run PAINTOR
```{r}
if(!dir.exists("out/paintor")) dir.create("out/paintor", recursive=T)
system(paste("../third_party/PAINTOR_V3.0/PAINTOR",
               "-input in/paintor/input.files",
               "-in in/paintor/",
               "-out out/paintor/",
               "-Zhead",  paste(collapse=',', paste0(names(sumstats),"_z")),
               "-LDname", paste(collapse=',', paste0("ld_",data_config$ancestry)),
               "-annotations dummy_annot",
               "-enumerate 1"
))
```
